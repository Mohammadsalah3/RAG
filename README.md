# ğŸŒ± RAG Assistant â€“ Multi-LLM (Ollama, OpenAI, Hugging Face)

A **Retrieval-Augmented Generation (RAG)** application that answers questions about **growing vegetables in Florida** using a vector database (**ChromaDB**) and multiple LLM providers.

The project supports:
- ğŸ–¥ï¸ Local LLMs via **Ollama**
- â˜ï¸ Cloud LLMs via **OpenAI**
- ğŸ¤— Open-source models via **Hugging Face**

A simple **Gradio UI** allows switching between models at runtime.

---

## ğŸš€ Features

- Retrieval-Augmented Generation (RAG)
- ChromaDB persistent vector store
- Multi-LLM routing (Local + Cloud)
- Anti-hallucination prompt design
- Gradio web interface
- Modular and extensible codebase

---

## ğŸ§  RAG Pipeline
- User Query
- ChromaDB (Top-K Retrieval)
- Context Construction
- LLM (Ollama / OpenAI / Hugging Face)
- Final Answer
---

## ğŸ› ï¸ Tech Stack

- **Python**
- **ChromaDB** â€“ Vector database
- **Ollama** â€“ Local LLM inference
- **OpenAI API**
- **Hugging Face Inference API**
- **Gradio** â€“ UI
